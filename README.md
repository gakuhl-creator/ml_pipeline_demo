# Churn Prediction ML Pipeline

A production-grade machine learning pipeline for customer churn prediction using:

- **Airflow** for orchestration
- **MLflow** for experiment tracking
- **Scikit-learn** for modeling
- **Jupyter Notebooks** for analysis
- **WSL + Python virtualenv** for environment isolation

---

## ğŸ“¦ Features

- Cleanly structured pipeline: `load â†’ preprocess â†’ train â†’ evaluate`
- Tracked and reproducible ML runs via MLflow
- Modular and maintainable Python package layout
- Configurable through a centralized `config.yaml`
- Ready for local or cloud deployment

---

## ğŸš€ Quickstart

### 1. Clone the Repository

```bash
git clone https://github.com/YOUR_USERNAME/gusto-ml-churn-pipeline.git
cd gusto-ml-churn-pipeline
```

### 2. Create Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Launch Airflow and MLflow

```bash
chmod +x start.sh
./start.sh
```

> This starts:
> - Airflow scheduler at `http://localhost:8080`
> - MLflow UI at `http://localhost:5000`

---

## ğŸ§  Pipeline Tasks

| Task          | Description                                   |
|---------------|-----------------------------------------------|
| `load_data.py`   | Load and persist raw input data as CSV       |
| `preprocess.py`  | Clean and encode features                    |
| `train_model.py` | Train RandomForest model + log to MLflow     |
| `evaluate.py`    | Evaluate test data + log metrics + plot      |

Each task is independently runnable and integrated into an Airflow DAG (`churn_pipeline`).

---

## ğŸ“ Folder Structure

```
ml_pipeline_demo/
â”œâ”€â”€ airflow/                  # DAGs and Airflow config
â”‚   â””â”€â”€ churn_dag.py
â”œâ”€â”€ data/                     # Input/output data
â”‚   â”œâ”€â”€ X.csv
â”‚   â”œâ”€â”€ y.csv
â”‚   â”œâ”€â”€ model.pkl
â”‚   â””â”€â”€ conf_matrix.png
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.yaml           # Central config for paths + MLflow
â”‚   â”œâ”€â”€ utils.py              # Config + path helpers
â”‚   â”œâ”€â”€ data_ingest/
â”‚   â”‚   â””â”€â”€ load_data.py
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ preprocess.py
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ train_model.py
â”‚       â””â”€â”€ evaluate.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ start.sh
â””â”€â”€ README.md
```

---

## ğŸ“Š MLflow Tracking

MLflow logs:

- Parameters: `n_estimators`, `max_depth`, etc.
- Metrics: `accuracy`, `precision`, `recall`, `f1`
- Artifacts: model pickle, confusion matrix image

Track at: [http://localhost:5000](http://localhost:5000)

---

## ğŸ§¬ Configuration (`config.yaml`)

```yaml
mlflow:
  tracking_uri: http://localhost:5000
  experiment_name: churn-prediction

paths:
  X: data/X.csv
  y: data/y.csv
  model: data/model.pkl
  confusion_matrix: data/conf_matrix.png
```

Update paths and experiment names here for easy portability.

---

## ğŸ› ï¸ Airflow Usage

From the UI at `http://localhost:8080`:

1. Turn on `churn_pipeline`
2. Trigger DAG manually
3. Monitor task logs and results

Or use CLI:

```bash
airflow dags trigger churn_pipeline
```

---

## âœ… Next Steps

- Track data versions and schema drift
- Deploy Model as API using Flask or FastAPI
- Containerize with Docker

---

## ğŸ§¾ License

MIT License
